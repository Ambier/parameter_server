# a sample configuration to run an optimized l1-regularized logistic regression solver
# see src/proto/app.proto for more details

type: RISK_MINIMIZATION
app_name: "proximal_gradient"
parameter_name: "proximal_gradient_weight"

training {
format: PROTO
# files: "../data/recordio/rcv1_part_.*"
files: "../data/recordio/ctr4m_part_.*"
## <regex> is supported by gcc-4.9, see https://gcc.gnu.org/gcc-4.9/changes.html
## but works on "Apple LLVM version 5.1 (clang-503.0.40) (based on LLVM 3.4svn)"
# files: "../data/recordio/ctr4m_part_[0-3]"
}

loss {
type: LOGIT
}

penalty {
type: L1
coefficient: 1
}

learner {
type: PROXIMAL_GRADIENT
learning_rate: .8
}

block_iterator {
# mini-batch updating. It is the number of examples in a block (mini-batch
# size), If <= 0, then use the whole data
example_block_size: -1

# block-coordinate updating. We divide a feature group into feature_block_ratio
# x nnz_feature_per_instance blocks. If = 0, then use all features
feature_block_ratio: 4

max_pass_of_data: 10

# bounded-delay consistency
max_block_delay: 1

# convergance critiria. stop if the relative objective <= epsilon
epsilon: 1e-3
}

block_coord_l1lr {

# kkt_filter_threshold = max_gradient_violation / num_examples *
# kkt_filter_threshold_ratio. increasing this number reduces the effect of kkt
# filter.
kkt_filter_threshold_ratio : 10
}
