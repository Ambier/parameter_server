# configuration to run l1-regularized logistic regression on the ctr dataset
type: RISK_MINIMIZATION
app_name: "ctr"
parameter_name: "ctr_w"

# training_data {
# format: TEXT
# text: ADFEA
# # file: "/proj/fawn/mu/ctrc/train/part-.*.gz"
# # file: "/proj/fawn/mu/ctrc/train/part-001.*.gz"
# }

training_data {
format: PROTO
# file: "../../data/ctrb/train/part-000[0-3].*"
file: "../../data/ctrb/train/part.*"
}

# validation_data {
# format: text
# text: adfea
# file: "../../../data/sampled_201405/test/part-00[0-1].gz"
# }


# each worker dumps its processed data into local disk (or hdfs). it will
# accelerate the data loading time if runing again. but remember to delete all
# caches if (1) # of workers is changed; (2) data are changed.
local_cache {
format: BIN
# file: "/l0/ctrc"
file: "../cache/ctrb"
}

# model_output {
# format: text
# }

loss {
type: LOGIT
}

# lambda * \| w \|_1
penalty {
type: L1
lambda: 5
}

learning_rate {
type: CONSTANT
eta: 1
}

block_solver {
# turn it off only for debug use
random_feature_block_order : true
# block-coordinate updating. we divide a feature group into feature_block_ratio
# x nnz_feature_per_instance blocks. if = 0, then use all features
feature_block_ratio : 4
# max # of iterations
max_pass_of_data : 6
# bounded-delay consistency
max_block_delay: 0
# convergance critiria. stop if the relative objective <= epsilon
epsilon : 2e-10
# important feature groups, update them eailer
prior_fea_group: 127            # the bias feature (all one)
prior_fea_group: 120            # the position rank feature
# features which occurs <= *tail_feature_count* will be filtered before training
tail_feature_count: 4
}

bcd_l1lr {
# trust region search
delta_init_value : 1
delta_max_value : 5
# increasing this number will reduce the effect of kkt filter. a very large
# number, such as 1e20 will turn off the kkt filter
kkt_filter_threshold_ratio : 10
}
