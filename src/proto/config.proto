package PS;
// configuration of data, model, and solver
import "proto/range.proto";
import "proto/neural_network.proto";

message AppConfig {
  enum Type {
    RISK_MINIMIZATION = 1;
    SKETCH = 2;
    NEURAL_NETWORK = 3;
  }
  optional Type type = 1;
  optional string app_name = 2;
  repeated string parameter_name = 3;

  // input / output
  optional DataConfig training_data = 10;
  optional DataConfig validation_data = 11;

  optional ParameterInitConfig init_w = 13;

  optional DataConfig model_output = 15;

  // risk minimization
  optional LossConfig loss = 20;
  optional PenaltyConfig penalty = 21;
  optional LearningRateConfig learning_rate = 23;

  optional LearnerConfig learner = 22;

  optional BlockSolverConfig block_solver = 24;

  optional BCDL1LRConfig bcd_l1lr = 25;

  // neural network
  optional NN.NetConfig nn = 30;
  optional NN.SolverConfig nn_solver = 31;

  // others
}

message DataConfig {
  enum DataFormat {
    BIN = 1;
    PROTO = 2;
    TEXT = 3;
  }
  required DataFormat format = 1;
  repeated string files = 2;
  optional PbRange range = 3;  // only valid for the binary format
}

message ParameterInitConfig {
  enum Type {
    ZERO = 1;
    RANDOM = 2;
    FILE = 3;
  }
  optional Type type = 1 [default = ZERO];
  optional double random_std = 2 [default = 1];
}

message BlockSolverConfig {
  // the number of example in a block. It is the minibatch size for
  // minibatch-sgd. If <= 0, then use the whole data
  optional int64 minibatch_size = 1 [default = 0];

  // divide a feature group into feature_block_ratio x nnz_feature_per_instance
  // blocks. If = 0, then use all features
  optional float feature_block_ratio = 2 [default = 0];

  // use a random order to updating feature block, it improves the
  // convergence. You may turn it off for debug use
  optional bool random_feature_block_order = 3 [default = true];

  optional int32 max_pass_of_data = 8 [default = 10];

  // bounded-delay consistency
  optional int32 max_block_delay = 10 [default = 0];

  // convergance critiria. stop if the relative objective <= epsilon
  optional double epsilon = 11 [default = 1e-4];

  // precision of auc, the larger the better
  optional int64 auc_goodness = 12 [default = 100000];
}


message BCDL1LRConfig {
  optional double delta_init_value = 1 [default = 1];
  optional double delta_max_value = 2 [default = 5];
  // optional bool KKT_filter = 1 [default = true];

  // kkt_filter_threshold = max_gradient_violation / num_examples *
  // kkt_filter_threshold_ratio. increasing this number reduces the effect of
  // kkt filter.
  optional double kkt_filter_threshold_ratio = 10 [default = 10];

}

message LossConfig {
  enum Type {
    SQUARE = 1;
    LOGIT = 2;
    HINGE = 3;
    SQUARE_HINGE = 4;
  }
  required Type type = 1;
}

message LearnerConfig {
  enum Type {
    GRADIENT_DESCENT = 1;
    PROXIMAL_GRADIENT = 2;
    LBFGS = 3;
  }
  required Type type = 1;
}

message PenaltyConfig {
  enum Type {
    L1 = 1;
    L2 = 2;
  }
  required Type type = 1;
  required float coefficient = 2 [default = 0];
}

message LearningRateConfig {
  enum Type {
    CONSTANT = 1;
  }
  required Type type = 1;
  optional double eta = 2 [default = 1];
}

message AggGradLearnerArg {
  optional double learning_rate = 1;
}
